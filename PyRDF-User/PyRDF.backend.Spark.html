<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: class Spark</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!-- Compiled and minified CSS -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-rc.2/css/materialize.min.css">

<!-- Compiled and minified JavaScript -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-rc.2/js/materialize.min.js"></script>

</head><body bgcolor="#f0f0f8">
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><strong>PyRDF.backend.Spark</strong> = <a name="PyRDF.backend.Spark">class Spark</a>(<a href="PyRDF.backend.Dist.html#Dist">PyRDF.backend.Dist.Dist</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Backend&nbsp;that&nbsp;executes&nbsp;the&nbsp;computational&nbsp;graph<br>
using&nbsp;using&nbsp;`Spark`&nbsp;framework&nbsp;for&nbsp;distributed<br>
execution.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="PyRDF.backend.Spark.html#Spark">Spark</a></dd>
<dd><a href="PyRDF.backend.Dist.html#Dist">PyRDF.backend.Dist.Dist</a></dd>
<dd><a href="PyRDF.backend.Backend.html#Backend">PyRDF.backend.Backend.Backend</a></dd>
<dd>abc.ABC</dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Spark-ProcessAndMerge"><strong>ProcessAndMerge</strong></a>(self, mapper, reducer)</dt><dd><tt>Performs&nbsp;map-reduce&nbsp;using&nbsp;Spark&nbsp;framework.<br>
&nbsp;<br>
Parameters<br>
----------<br>
mapper&nbsp;:&nbsp;function<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;function&nbsp;that&nbsp;runs&nbsp;the&nbsp;computational&nbsp;graph<br>
&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;returns&nbsp;a&nbsp;list&nbsp;of&nbsp;values.<br>
&nbsp;<br>
reducer&nbsp;:&nbsp;function<br>
&nbsp;&nbsp;&nbsp;&nbsp;A&nbsp;function&nbsp;that&nbsp;merges&nbsp;two&nbsp;lists&nbsp;that&nbsp;were<br>
&nbsp;&nbsp;&nbsp;&nbsp;returned&nbsp;by&nbsp;the&nbsp;mapper.<br>
&nbsp;<br>
Returns<br>
-------<br>
list<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;list&nbsp;represents&nbsp;the&nbsp;values&nbsp;of&nbsp;action&nbsp;nodes<br>
&nbsp;&nbsp;&nbsp;&nbsp;returned&nbsp;after&nbsp;computation&nbsp;(Map-Reduce).</tt></dd></dl>

<dl><dt><a name="Spark-__init__"><strong>__init__</strong></a>(self, config={})</dt><dd><tt>Creates&nbsp;an&nbsp;instance&nbsp;of&nbsp;the&nbsp;Spark<br>
backend&nbsp;class.<br>
&nbsp;<br>
Parameters<br>
----------<br>
config&nbsp;:&nbsp;dict&nbsp;(optional)<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;config&nbsp;options&nbsp;for&nbsp;Spark&nbsp;backend.&nbsp;The&nbsp;default<br>
&nbsp;&nbsp;&nbsp;&nbsp;value&nbsp;is&nbsp;an&nbsp;empty&nbsp;Python&nbsp;dictionary&nbsp;`{}`.&nbsp;Config<br>
&nbsp;&nbsp;&nbsp;&nbsp;should&nbsp;be&nbsp;a&nbsp;dictionary&nbsp;of&nbsp;Spark&nbsp;configuration<br>
&nbsp;&nbsp;&nbsp;&nbsp;options&nbsp;and&nbsp;their&nbsp;values&nbsp;with&nbsp;'npartitions'&nbsp;as<br>
&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;only&nbsp;allowed&nbsp;extra&nbsp;parameter.<br>
&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;example&nbsp;:-<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;config&nbsp;=&nbsp;{<br>
&nbsp;&nbsp;&nbsp;&nbsp;'npartitions':20,<br>
&nbsp;&nbsp;&nbsp;&nbsp;'spark.master':'myMasterURL',<br>
&nbsp;&nbsp;&nbsp;&nbsp;'spark.executor.instances':10,<br>
&nbsp;&nbsp;&nbsp;&nbsp;'spark.app.name':'mySparkAppName'<br>
&nbsp;&nbsp;&nbsp;&nbsp;}<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;IMPORTANT&nbsp;NOTE&nbsp;:-&nbsp;If&nbsp;a&nbsp;SparkContext&nbsp;is&nbsp;already&nbsp;set<br>
&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;the&nbsp;current&nbsp;environment,&nbsp;the&nbsp;Spark&nbsp;configuration<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameters&nbsp;from&nbsp;'config'&nbsp;will&nbsp;be&nbsp;ignored&nbsp;and&nbsp;the&nbsp;already<br>
&nbsp;&nbsp;&nbsp;&nbsp;existing&nbsp;SparkContext&nbsp;would&nbsp;be&nbsp;used.</tt></dd></dl>

<hr>
Data and other attributes defined here:<br>
<dl><dt><strong>__abstractmethods__</strong> = frozenset()</dl>

<hr>
Methods inherited from <a href="PyRDF.backend.Dist.html#Dist">PyRDF.backend.Dist.Dist</a>:<br>
<dl><dt><a name="Spark-BuildRanges"><strong>BuildRanges</strong></a>(self, nentries, npartitions)</dt><dd><tt>Builds&nbsp;range&nbsp;pairs&nbsp;from&nbsp;the&nbsp;given&nbsp;values<br>
of&nbsp;the&nbsp;number&nbsp;of&nbsp;entries&nbsp;in&nbsp;the&nbsp;dataset&nbsp;and<br>
number&nbsp;of&nbsp;partitions&nbsp;required.<br>
&nbsp;<br>
Parameters<br>
----------<br>
nentries&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;entries&nbsp;in&nbsp;a&nbsp;dataset.<br>
&nbsp;<br>
npartitions&nbsp;:&nbsp;int<br>
&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;number&nbsp;of&nbsp;parallel&nbsp;computations.<br>
&nbsp;<br>
Returns<br>
-------<br>
list<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;is&nbsp;a&nbsp;list&nbsp;of&nbsp;range&nbsp;pairs&nbsp;(represented&nbsp;here<br>
&nbsp;&nbsp;&nbsp;&nbsp;as&nbsp;2-member&nbsp;tuples).</tt></dd></dl>

<dl><dt><a name="Spark-execute"><strong>execute</strong></a>(self, generator)</dt><dd><tt>Executes&nbsp;the&nbsp;current&nbsp;RDataFrame&nbsp;graph<br>
in&nbsp;the&nbsp;given&nbsp;distributed&nbsp;environment.<br>
&nbsp;<br>
Parameters<br>
----------<br>
generator&nbsp;:&nbsp;PyRDF.CallableGenerator<br>
&nbsp;&nbsp;&nbsp;&nbsp;An&nbsp;instance&nbsp;of&nbsp;type&nbsp;`CallableGenerator`&nbsp;that&nbsp;is<br>
&nbsp;&nbsp;&nbsp;&nbsp;responsible&nbsp;for&nbsp;generating&nbsp;the&nbsp;callable&nbsp;function.</tt></dd></dl>

<hr>
Methods inherited from <a href="PyRDF.backend.Backend.html#Backend">PyRDF.backend.Backend.Backend</a>:<br>
<dl><dt><a name="Spark-check_supported"><strong>check_supported</strong></a>(self, operation_name)</dt><dd><tt>Checks&nbsp;if&nbsp;a&nbsp;given&nbsp;operation&nbsp;is&nbsp;supported<br>
by&nbsp;the&nbsp;given&nbsp;backend.<br>
&nbsp;<br>
Parameters<br>
----------<br>
operation_name<br>
&nbsp;&nbsp;&nbsp;&nbsp;Name&nbsp;of&nbsp;the&nbsp;operation&nbsp;to&nbsp;be&nbsp;checked.<br>
&nbsp;<br>
Raises<br>
------<br>
Exception<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;happens&nbsp;when&nbsp;`operation_name`&nbsp;doesn't<br>
&nbsp;&nbsp;&nbsp;&nbsp;exist&nbsp;in&nbsp;`supported_operations`&nbsp;instance&nbsp;member.</tt></dd></dl>

<hr>
Data and other attributes inherited from <a href="PyRDF.backend.Backend.html#Backend">PyRDF.backend.Backend.Backend</a>:<br>
<dl><dt><strong>supported_operations</strong> = ['Define', 'Filter', 'Histo1D', 'Histo2D', 'Histo3D', 'Profile1D', 'Profile2D', 'Profile3D', 'Count', 'Min', 'Max', 'Mean', 'Sum', 'Fill', 'Report', 'Range', 'Take', 'Snapshot', 'Foreach', 'Reduce', ...]</dl>

<hr>
Data descriptors inherited from abc.ABC:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table>
</body></html>